{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "This file covers the solutions to the 3 questions on assignment 2.\n",
    "1. Implement C4.5 decision tree classifier.\n",
    "2. Evaluate the impact of noise on C4.5 decision tree classifier.\n",
    "3. Design a feature selection algorithm and apply to MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.linalg as sl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from mlxtend.data import loadlocal_mnist\n",
    "from anytree import Node, RenderTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load glass and tic tac toe datasets\n",
    "glass_dataframe = pandas.read_csv('datasets/glass.data', header=None, engine='python')\n",
    "tictactoe_dataframe = pandas.read_csv('datasets/tic-tac-toe.data', header=None, engine='python')\n",
    "\n",
    "# label encoding for tictactoe targets\n",
    "le = LabelEncoder()\n",
    "tictactoe_dataframe[9] = le.fit_transform(tictactoe_dataframe[9])\n",
    "\n",
    "# seperate featres from targets\n",
    "glass_X = glass_dataframe.iloc[:,1:-1].values\n",
    "glass_Y = glass_dataframe.iloc[:,-1].values\n",
    "tictactoe_X = tictactoe_dataframe.iloc[:,:-1].values\n",
    "tictactoe_Y = tictactoe_dataframe.iloc[:,-1].values\n",
    "\n",
    "# feature names for each datset\n",
    "glass_feature_names = np.array(['RI', 'Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe'])\n",
    "\n",
    "tictactoe_feature_names = np.array(['top-left', 'top-middle', 'top-right',\n",
    "                          'middle-left', 'middle-middle', 'middle-right',\n",
    "                          'bottom-left', 'bottom-middle', 'bottom-right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     214\n",
       "1     178\n",
       "2     142\n",
       "3      94\n",
       "4     118\n",
       "5     133\n",
       "6      65\n",
       "7     143\n",
       "8      34\n",
       "9      32\n",
       "10      6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glass_dataframe.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 214 entries, 0 to 213\n",
      "Data columns (total 11 columns):\n",
      "0     214 non-null int64\n",
      "1     214 non-null float64\n",
      "2     214 non-null float64\n",
      "3     214 non-null float64\n",
      "4     214 non-null float64\n",
      "5     214 non-null float64\n",
      "6     214 non-null float64\n",
      "7     214 non-null float64\n",
      "8     214 non-null float64\n",
      "9     214 non-null float64\n",
      "10    214 non-null int64\n",
      "dtypes: float64(9), int64(2)\n",
      "memory usage: 18.5 KB\n"
     ]
    }
   ],
   "source": [
    "glass_dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 958 entries, 0 to 957\n",
      "Data columns (total 10 columns):\n",
      "0    958 non-null object\n",
      "1    958 non-null object\n",
      "2    958 non-null object\n",
      "3    958 non-null object\n",
      "4    958 non-null object\n",
      "5    958 non-null object\n",
      "6    958 non-null object\n",
      "7    958 non-null object\n",
      "8    958 non-null object\n",
      "9    958 non-null int32\n",
      "dtypes: int32(1), object(9)\n",
      "memory usage: 71.2+ KB\n"
     ]
    }
   ],
   "source": [
    "tictactoe_dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08718670223056812"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# information gain debugging\n",
    "data = tictactoe_X[:,4]\n",
    "idx_subsets = []\n",
    "for feature_val in np.unique(data):\n",
    "    idx_subset = np.argwhere(data == feature_val).ravel()\n",
    "    idx_subsets.append(idx_subset)\n",
    "subsets = [tictactoe_Y[idx] for idx in idx_subsets]\n",
    "\n",
    "informationGain(tictactoe_Y, subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['middle-middle']\n",
      "[160, 340, 458]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "958"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best feature selection debugging\n",
    "ft_idx, ft_split, ft_threshold, ft_discrete = selectBestAttribute(tictactoe_X, tictactoe_Y, tictactoe_feature_names)\n",
    "lengths = [len(x) for x in ft_split]\n",
    "print(tictactoe_feature_names[ft_idx])\n",
    "print(lengths)\n",
    "sum(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement C4.5 Decision Tree\n",
    "def buildTree(x, y, features):\n",
    "    numfeatures = len(features)\n",
    "    numsamples = x.shape[0]\n",
    "    \n",
    "    # base case 1: check if attribute list empty\n",
    "    if len(features) == 0:\n",
    "        isLeafNode= True\n",
    "        majorityClass = np.bincount(y).argmax()\n",
    "        return dtNode(None, isLeafNode, majorityClass, None, None)\n",
    "    \n",
    "    # base case 2: check if all samples are of the same class\n",
    "    elif len(set(y)) == 1:\n",
    "        isLeafNode= True\n",
    "        classLabel = y[0]\n",
    "        return dtNode(None, isLeafNode, classLabel, None, None)\n",
    "    \n",
    "    # select next best feature and make recursive call to branch out\n",
    "    else:\n",
    "        isLeafNode = False\n",
    "        majorityClass = np.bincount(y).argmax()\n",
    "        feature_idx, feature_splits, threshold, isFeatureDiscrete = selectBestAttribute(x, y, features)\n",
    "        \n",
    "        # determine remaining features and remove best feature selected\n",
    "        new_features = np.delete(features, feature_idx)\n",
    "        new_x = np.delete(x, feature_idx, axis=1)\n",
    "        \n",
    "        # iterate over feature splits and create child nodes\n",
    "        node = dtNode(threshold, isLeafNode, majorityClass, features[feature_idx], isFeatureDiscrete)\n",
    "        for split in feature_splits:\n",
    "            node.childNodes.append(buildTree(new_x[split], y[split], new_features))\n",
    "        return node\n",
    "        \n",
    "\n",
    "# select best attribute based on gain ratio\n",
    "def selectBestAttribute(x, y, features):\n",
    "    best_feature_idx = None\n",
    "    best_feature_splits = None\n",
    "    best_feature_threshold = None\n",
    "    best_feature_discrete = None\n",
    "    best_gain = -np.inf\n",
    "    \n",
    "    for feature in features:\n",
    "        feature_idx = np.argwhere(features == feature).ravel()\n",
    "        data = x[:,feature_idx].ravel()\n",
    "        \n",
    "        # dealing with discrete features\n",
    "        isFeatureDiscrete = isDiscrete(data)\n",
    "        if isFeatureDiscrete:\n",
    "            feature_values = np.unique(data)\n",
    "            idx_subsets = []\n",
    "            for feature_val in feature_values:\n",
    "                idx_subset = np.argwhere(data == feature_val).ravel()\n",
    "                idx_subsets.append(idx_subset)\n",
    "            y_subsets = [y[idx] for idx in idx_subsets]\n",
    "            \n",
    "            gain = informationGain(y, y_subsets)\n",
    "            if gain > best_gain:\n",
    "                best_gain = gain\n",
    "                best_feature_idx = feature_idx\n",
    "                best_feature_splits = idx_subsets\n",
    "                best_feature_threshold = feature_values\n",
    "                best_feature_discrete = True\n",
    "        \n",
    "        # dealing with continuous features\n",
    "        else:\n",
    "            sortedData = np.sort(data)\n",
    "            \n",
    "            # iterate over all possible thresholds\n",
    "            for i in range(len(sortedData)-1):\n",
    "                if sortedData[i] != sortedData[i+1]:\n",
    "                    pickThreshold = (sortedData[i] + sortedData[i+1]) / 2\n",
    "                    leftIdx = np.argwhere(data <= pickThreshold).ravel()\n",
    "                    rightIdx = np.argwhere(data > pickThreshold).ravel()\n",
    "                    \n",
    "                    idx_subsets = [leftIdx, rightIdx]\n",
    "                    y_subsets = [y[idx] for idx in idx_subsets]\n",
    "                                      \n",
    "                    gain = informationGain(y, y_subsets)\n",
    "                    if gain > best_gain:\n",
    "                        best_gain = gain\n",
    "                        best_feature_idx = feature_idx\n",
    "                        best_feature_splits = idx_subsets\n",
    "                        best_feature_threshold = pickThreshold\n",
    "                        best_feature_discrete = False\n",
    "    \n",
    "    return (best_feature_idx, best_feature_splits, best_feature_threshold, best_feature_discrete)\n",
    "\n",
    "# check if feature is discrete or continuous using threshold of 10\n",
    "def isDiscrete(data):\n",
    "    if len(np.unique(data)) < 10:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "        \n",
    "    \n",
    "# gain ratio\n",
    "def gainRatio():\n",
    "    return informationGain() / splitInformation()\n",
    "\n",
    "# information gain\n",
    "def informationGain(y, y_subsets):\n",
    "    numsamples = len(y)\n",
    "    numsubsets = len(y_subsets)\n",
    "    \n",
    "    # calculate initialEntropy\n",
    "    initialEntropy = entropy(y)\n",
    "    \n",
    "    # calculate afterEntropy\n",
    "    afterEntropy = 0\n",
    "    for i in range(numsubsets):\n",
    "        subset_weight = len(y_subsets[i]) / numsamples\n",
    "        afterEntropy += subset_weight * entropy(y_subsets[i])\n",
    "    \n",
    "    return initialEntropy - afterEntropy\n",
    "\n",
    "# split information\n",
    "def splitInformation():\n",
    "    pass\n",
    "\n",
    "# entropy calculation\n",
    "def entropy(y):\n",
    "    counts = np.bincount(y)\n",
    "    probabilities = counts[np.nonzero(counts)] / float(len(y))\n",
    "    return sp.stats.entropy(probabilities, base=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the class_label of sample given the C4.5 tree\n",
    "def predictClass(dt, x, feature_names):\n",
    "    currNode = dt\n",
    "    leafNode = dt.isLeafNode\n",
    "    while not leafNode:\n",
    "        idx = np.argwhere(feature_names == currNode.feature).ravel()\n",
    "        \n",
    "        # handling decision node that is discrete\n",
    "        if currNode.isFeatureDiscrete:\n",
    "            split_idx = np.argwhere(currNode.threshold == x[idx]).ravel()\n",
    "            \n",
    "            if len(split_idx):\n",
    "                currNode = currNode.childNodes[split_idx[0]]\n",
    "                leafNode = currNode.isLeafNode\n",
    "                \n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        # handling decision node that is continuous\n",
    "        else: \n",
    "            if x[idx] <= currNode.threshold:\n",
    "                currNode = currNode.childNodes[0] # go left in the decision path\n",
    "            else:\n",
    "                currNode = currNode.childNodes[1] # go right in the decision path\n",
    "\n",
    "            leafNode = currNode.isLeafNode\n",
    "    \n",
    "    y_pred = currNode.label\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree class that uses C4.5 implementation\n",
    "class DecisionTree:\n",
    "    \n",
    "    # if hyperparamters required, they are to be added here (ex. max_depth)\n",
    "    def __init__(self, feature_names):\n",
    "        self.clf = None\n",
    "        self.feature_names = feature_names\n",
    "    \n",
    "    def fit(self, x_train, y_train):\n",
    "        self.clf = buildTree(x_train, y_train, self.feature_names)\n",
    "    \n",
    "    def predict(self, x_test):\n",
    "        y_pred = []\n",
    "        for x in x_test:\n",
    "            y_pred.append(predictClass(self.clf, x, self.feature_names))\n",
    "            \n",
    "        return y_pred\n",
    "\n",
    "    \n",
    "# decision tree node that defines threshold, isLeafNode, class_label and childNodes list\n",
    "class dtNode:\n",
    "    \n",
    "    def __init__(self, threshold, isLeafNode, label, feature, isFeatureDiscrete):\n",
    "        self.threshold = threshold # threshold for the decision path, None if isLeafNode\n",
    "        self.isLeafNode = isLeafNode  # if current node is a leaf (terminal) node\n",
    "        self.label = label  # the class label, if not isLeafNode it is the majority class label\n",
    "        self.feature = feature # if not isLeafNode it is the feature to split on, otherwise None\n",
    "        self.isFeatureDiscrete = isFeatureDiscrete # check feature discrete or continuous, None if isLeafNode\n",
    "        self.childNodes = []\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform CV with given number of iterations and folds\n",
    "def crossvalidation(clf, X, Y, iters=10, k=10):\n",
    "    numsamples = X.shape[0]\n",
    "\n",
    "    accuracy_scores = []\n",
    "    for i in range(iters):\n",
    "\n",
    "        # single iteration of k-fold CV\n",
    "        idxs = np.arange(numsamples)\n",
    "        folds = np.random.choice(idxs, size=(k, int(numsamples/k)), replace=False)\n",
    "\n",
    "        # obtain accuracy scores for k-fold CV\n",
    "        kfold_accuracy_scores = []\n",
    "        for j in range(k):\n",
    "            test_idx = folds[j]\n",
    "            train_idx = np.delete(folds, j, axis=0).ravel()\n",
    "\n",
    "            clf.fit(X[train_idx], Y[train_idx])\n",
    "            y_pred = clf.predict(X[test_idx])\n",
    "\n",
    "            accuracy = accuracy_score(Y[test_idx], y_pred)\n",
    "            kfold_accuracy_scores.append(accuracy)\n",
    "\n",
    "        accuracy_scores.append(np.mean(kfold_accuracy_scores))\n",
    "    \n",
    "    return accuracy_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build classifier on glass dataset\n",
    "glass_clf = DecisionTree(glass_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glass Dataset\n",
      "10 times 10 fold CV: (0.95 CI)\n",
      "------------------------------\n",
      "Accuracy: 0.654 +/- 0.028\n"
     ]
    }
   ],
   "source": [
    "# do 10 times 10 CV on tic glass dataset\n",
    "accuracy_scores = crossvalidation(glass_clf, glass_X, glass_Y, iters=10, k=10)\n",
    "\n",
    "print(\"Glass Dataset\")\n",
    "print(\"10 times 10 fold CV: (0.95 CI)\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Accuracy: {np.mean(accuracy_scores):.3f} +/- {2*np.std(accuracy_scores, ddof=0):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build classifier on tic tac toe dataset\n",
    "tictactoe_clf = DecisionTree(tictactoe_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tic Tac Toe Dataset\n",
      "10 times 10 fold CV: (0.95 CI)\n",
      "------------------------------\n",
      "Accuracy: 0.857 +/- 0.021\n"
     ]
    }
   ],
   "source": [
    "# do 10 times 10 CV on tic tac toe dataset\n",
    "accuracy_scores = crossvalidation(tictactoe_clf, tictactoe_X, tictactoe_Y, iters=10, k=10)\n",
    "\n",
    "print(\"Tic Tac Toe Dataset\")\n",
    "print(\"10 times 10 fold CV: (0.95 CI)\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Accuracy: {np.mean(accuracy_scores):.3f} +/- {2*np.std(accuracy_scores, ddof=0):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mnist dataset\n",
    "X_train, Y_train = loadlocal_mnist(\n",
    "        images_path='datasets/train-images.idx3-ubyte', \n",
    "        labels_path='datasets/train-labels.idx1-ubyte')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:syde675-project]",
   "language": "python",
   "name": "conda-env-syde675-project-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
