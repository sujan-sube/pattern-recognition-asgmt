{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "This file covers the solutions to the 3 questions on assignment 2.\n",
    "1. Implement C4.5 decision tree classifier.\n",
    "2. Evaluate the impact of noise on C4.5 decision tree classifier.\n",
    "3. Design a feature selection algorithm and apply to MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.linalg as sl\n",
    "from scipy.spatial.distance import cdist\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from mlxtend.data import loadlocal_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load glass and tic tac toe datasets\n",
    "glass_dataframe = pandas.read_csv('datasets/glass.data', header=None, engine='python')\n",
    "tictactoe_dataframe = pandas.read_csv('datasets/tic-tac-toe.data', header=None, engine='python')\n",
    "\n",
    "# label encoding for tictactoe targets\n",
    "le = LabelEncoder()\n",
    "tictactoe_dataframe[9] = le.fit_transform(tictactoe_dataframe[9])\n",
    "\n",
    "# seperate featres from targets\n",
    "glass_X = glass_dataframe.iloc[:,1:-1].values\n",
    "glass_Y = glass_dataframe.iloc[:,-1].values\n",
    "tictactoe_X = tictactoe_dataframe.iloc[:,:-1].values\n",
    "tictactoe_Y = tictactoe_dataframe.iloc[:,-1].values\n",
    "\n",
    "# feature names for each datset\n",
    "glass_feature_names = np.array(['RI', 'Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe'])\n",
    "\n",
    "tictactoe_feature_names = np.array(['top-left', 'top-middle', 'top-right',\n",
    "                          'middle-left', 'middle-middle', 'middle-right',\n",
    "                          'bottom-left', 'bottom-middle', 'bottom-right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     214\n",
       "1     178\n",
       "2     142\n",
       "3      94\n",
       "4     118\n",
       "5     133\n",
       "6      65\n",
       "7     143\n",
       "8      34\n",
       "9      32\n",
       "10      6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glass_dataframe.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 214 entries, 0 to 213\n",
      "Data columns (total 11 columns):\n",
      "0     214 non-null int64\n",
      "1     214 non-null float64\n",
      "2     214 non-null float64\n",
      "3     214 non-null float64\n",
      "4     214 non-null float64\n",
      "5     214 non-null float64\n",
      "6     214 non-null float64\n",
      "7     214 non-null float64\n",
      "8     214 non-null float64\n",
      "9     214 non-null float64\n",
      "10    214 non-null int64\n",
      "dtypes: float64(9), int64(2)\n",
      "memory usage: 18.5 KB\n"
     ]
    }
   ],
   "source": [
    "glass_dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 958 entries, 0 to 957\n",
      "Data columns (total 10 columns):\n",
      "0    958 non-null object\n",
      "1    958 non-null object\n",
      "2    958 non-null object\n",
      "3    958 non-null object\n",
      "4    958 non-null object\n",
      "5    958 non-null object\n",
      "6    958 non-null object\n",
      "7    958 non-null object\n",
      "8    958 non-null object\n",
      "9    958 non-null int32\n",
      "dtypes: int32(1), object(9)\n",
      "memory usage: 71.2+ KB\n"
     ]
    }
   ],
   "source": [
    "tictactoe_dataframe.info()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# information gain, split information and gain ratio debugging\n",
    "data = tictactoe_X[:,4]\n",
    "idx_subsets = []\n",
    "for feature_val in np.unique(data):\n",
    "#     idx_subset = np.argwhere(data == feature_val).ravel()\n",
    "    idx_subsets.append(idx_subset)\n",
    "subsets = [tictactoe_Y[idx] for idx in idx_subsets]\n",
    "\n",
    "gainRatio(tictactoe_Y, subsets)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# best feature selection debugging\n",
    "ft_idx, ft_split, ft_threshold, ft_discrete = selectBestAttribute(tictactoe_X, tictactoe_Y, tictactoe_feature_names)\n",
    "lengths = [len(x) for x in ft_split]\n",
    "print(tictactoe_feature_names[ft_idx])\n",
    "print(lengths)\n",
    "sum(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement C4.5 Decision Tree\n",
    "def buildTree(x, y, features):\n",
    "    numfeatures = len(features)\n",
    "    numsamples = x.shape[0]\n",
    "    \n",
    "    # base case 1: check if attribute list empty\n",
    "    if len(features) == 0:\n",
    "        isLeafNode= True\n",
    "        majorityClass = np.bincount(y).argmax()\n",
    "        return dtNode(None, isLeafNode, majorityClass, None, None)\n",
    "    \n",
    "    # base case 2: check if all samples are of the same class\n",
    "    elif len(set(y)) == 1:\n",
    "        isLeafNode= True\n",
    "        classLabel = y[0]\n",
    "        return dtNode(None, isLeafNode, classLabel, None, None)\n",
    "    \n",
    "    # select next best feature and make recursive call to branch out\n",
    "    else:\n",
    "        isLeafNode = False\n",
    "        majorityClass = np.bincount(y).argmax()\n",
    "        feature_idx, feature_splits, threshold, isFeatureDiscrete = selectBestAttribute(x, y, features)\n",
    "        \n",
    "        # determine remaining features and remove best feature selected\n",
    "        new_features = np.delete(features, feature_idx)\n",
    "        new_x = np.delete(x, feature_idx, axis=1)\n",
    "        \n",
    "        # iterate over feature splits and create child nodes\n",
    "        node = dtNode(threshold, isLeafNode, majorityClass, features[feature_idx], isFeatureDiscrete)\n",
    "        for split in feature_splits:\n",
    "            node.childNodes.append(buildTree(new_x[split], y[split], new_features))\n",
    "        return node\n",
    "        \n",
    "\n",
    "# select best attribute based on gain ratio\n",
    "def selectBestAttribute(x, y, features):\n",
    "    best_feature_idx = None\n",
    "    best_feature_splits = None\n",
    "    best_feature_threshold = None\n",
    "    best_feature_discrete = None\n",
    "    best_gain = -np.inf\n",
    "    \n",
    "    for feature in features:\n",
    "        feature_idx = np.argwhere(features == feature).ravel()\n",
    "        data = x[:,feature_idx].ravel()\n",
    "        \n",
    "        # dealing with discrete features\n",
    "        isFeatureDiscrete = isDiscrete(data)\n",
    "        if isFeatureDiscrete:\n",
    "            feature_values = np.unique(data)\n",
    "            idx_subsets = []\n",
    "            for feature_val in feature_values:\n",
    "                idx_subset = np.argwhere(data == feature_val).ravel()\n",
    "                idx_subsets.append(idx_subset)\n",
    "            y_subsets = [y[idx] for idx in idx_subsets]\n",
    "            \n",
    "            gain = informationGain(y, y_subsets)\n",
    "            if gain > best_gain:\n",
    "                best_gain = gain\n",
    "                best_feature_idx = feature_idx\n",
    "                best_feature_splits = idx_subsets\n",
    "                best_feature_threshold = feature_values\n",
    "                best_feature_discrete = True\n",
    "        \n",
    "        # dealing with continuous features\n",
    "        else:\n",
    "            sortedData = np.sort(data)\n",
    "            \n",
    "            # iterate over all possible thresholds\n",
    "            for i in range(len(sortedData)-1):\n",
    "                if sortedData[i] != sortedData[i+1]:\n",
    "                    pickThreshold = (sortedData[i] + sortedData[i+1]) / 2\n",
    "                    leftIdx = np.argwhere(data <= pickThreshold).ravel()\n",
    "                    rightIdx = np.argwhere(data > pickThreshold).ravel()\n",
    "                    \n",
    "                    idx_subsets = [leftIdx, rightIdx]\n",
    "                    y_subsets = [y[idx] for idx in idx_subsets]\n",
    "                                      \n",
    "                    gain = gainRatio(y, y_subsets)\n",
    "                    if gain > best_gain:\n",
    "                        best_gain = gain\n",
    "                        best_feature_idx = feature_idx\n",
    "                        best_feature_splits = idx_subsets\n",
    "                        best_feature_threshold = pickThreshold\n",
    "                        best_feature_discrete = False\n",
    "    \n",
    "    return (best_feature_idx, best_feature_splits, best_feature_threshold, best_feature_discrete)\n",
    "\n",
    "# check if feature is discrete or continuous using threshold of 10\n",
    "def isDiscrete(data):\n",
    "    if len(np.unique(data)) <= 3:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "# gain ratio\n",
    "def gainRatio(y, y_subsets):\n",
    "    return informationGain(y, y_subsets) / splitInformation(y, y_subsets)\n",
    "\n",
    "# information gain criteria\n",
    "def informationGain(y, y_subsets):\n",
    "    numsamples = len(y)\n",
    "    numsubsets = len(y_subsets)\n",
    "    \n",
    "    # calculate initialEntropy\n",
    "    initialEntropy = entropy(y)\n",
    "    \n",
    "    # calculate afterEntropy\n",
    "    afterEntropy = 0\n",
    "    for i in range(numsubsets):\n",
    "        subset_weight = len(y_subsets[i]) / numsamples\n",
    "        afterEntropy += subset_weight * entropy(y_subsets[i])\n",
    "    \n",
    "    return initialEntropy - afterEntropy\n",
    "\n",
    "# split information criteria\n",
    "def splitInformation(y, y_subsets):\n",
    "    numsamples = len(y)\n",
    "    numsubsets = len(y_subsets)\n",
    "    \n",
    "    SI = []\n",
    "    for i in range(numsubsets):\n",
    "        subset_ratio = len(y_subsets[i]) / numsamples\n",
    "        SI_v = subset_ratio * np.log2(subset_ratio)\n",
    "        SI.append(SI_v)\n",
    "        \n",
    "    return -np.sum(SI)\n",
    "\n",
    "# entropy calculation\n",
    "def entropy(y):\n",
    "    counts = np.bincount(y)\n",
    "    probabilities = counts[np.nonzero(counts)] / float(len(y))\n",
    "    return sp.stats.entropy(probabilities, base=2)\n",
    "\n",
    "# convert decision tree to list of rules\n",
    "def convertTreeToListOfRules(dt):\n",
    "    \n",
    "    # base case\n",
    "    if dt.isLeafNode:\n",
    "        rule = Rule(dt.label)\n",
    "        return rule\n",
    "    \n",
    "    # add rules from each node\n",
    "    else:\n",
    "        res = []\n",
    "            \n",
    "        # handling decision node that is discrete\n",
    "        if dt.isFeatureDiscrete:\n",
    "            for child, discrete_value in zip(dt.childNodes, dt.threshold):\n",
    "                rules = convertTreeToListOfRules(child)\n",
    "                rules = rules if type(rules) == list else [rules]\n",
    "                \n",
    "                for r in rules:\n",
    "                    condition = [dt.label, 'e', discrete_value]\n",
    "                    r.prependCondition(condition)\n",
    "                    \n",
    "                res += rules\n",
    "\n",
    "        # handling decision node that is continuous\n",
    "        else:\n",
    "            ops = ['le', 'g']\n",
    "            continuous_value = dt.threshold\n",
    "            \n",
    "            for child, op in zip(dt.childNodes, ops):\n",
    "                rules = convertTreeToListOfRules(child)\n",
    "                rules = rules if type(rules) == list else [rules]\n",
    "\n",
    "                for r in rules:\n",
    "                    condition = [dt.label, op, continuous_value]\n",
    "                    r.prependCondition(condition)\n",
    "                    \n",
    "                res += rules\n",
    "                \n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debugging convert to rules - DEBUG CODE\n",
    "glass_dt = DecisionTree(glass_feature_names)\n",
    "glass_dt.fit(glass_X, glass_Y)\n",
    "glass_dt.prune(glass_X, glass_Y)\n",
    "# rules_dt = convertTreeToListOfRules(glass_dt.clf)\n",
    "# glass_dt.clf.childNodes[1].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2: [[2, 'le', 0.335], [2, 'le', 2.56], [2, 'le', 0.03], [6, 'le', 13.754999999999999]]\n",
      "6: [[2, 'le', 0.335], [2, 'le', 2.56], [2, 'le', 0.03], [6, 'g', 13.754999999999999]]\n",
      "2: [[2, 'le', 0.335], [2, 'le', 2.56], [2, 'g', 0.03], [5, 'le', 14.645], [5, 'le', 74.53], [5, 'le', 1.38]]\n",
      "5: [[2, 'le', 0.335], [2, 'le', 2.56], [2, 'g', 0.03], [5, 'le', 14.645], [5, 'le', 74.53], [5, 'g', 1.38], [5, 'le', 0.085]]\n",
      "2: [[2, 'le', 0.335], [2, 'le', 2.56], [2, 'g', 0.03], [5, 'le', 14.645], [5, 'le', 74.53], [5, 'g', 1.38], [5, 'g', 0.085], [2, 'le', 1.52039]]\n",
      "2: [[2, 'le', 0.335], [2, 'le', 2.56], [2, 'g', 0.03], [5, 'le', 14.645], [5, 'le', 74.53], [5, 'g', 1.38], [5, 'g', 0.085], [2, 'g', 1.52039], [2, 'le', 9.635]]\n",
      "2: [[2, 'le', 0.335], [2, 'le', 2.56], [2, 'g', 0.03], [5, 'le', 14.645], [5, 'le', 74.53], [5, 'g', 1.38], [5, 'g', 0.085], [2, 'g', 1.52039], [2, 'g', 9.635]]\n",
      "7: [[2, 'le', 0.335], [2, 'le', 2.56], [2, 'g', 0.03], [5, 'le', 14.645], [5, 'g', 74.53]]\n",
      "7: [[2, 'le', 0.335], [2, 'le', 2.56], [2, 'g', 0.03], [5, 'g', 14.645]]\n",
      "3: [[2, 'le', 0.335], [2, 'g', 2.56], [1, 'le', 12.18]]\n",
      "2: [[2, 'le', 0.335], [2, 'g', 2.56], [1, 'g', 12.18], [1, 'le', 0.36], [1, 'le', 1.42], [1, 'le', 71.25]]\n",
      "3: [[2, 'le', 0.335], [2, 'g', 2.56], [1, 'g', 12.18], [1, 'le', 0.36], [1, 'le', 1.42], [1, 'g', 71.25], [1, 'le', 1.523075], [1, 'le', 0.165], [1, 'le', 8.675]]\n",
      "1: [[2, 'le', 0.335], [2, 'g', 2.56], [1, 'g', 12.18], [1, 'le', 0.36], [1, 'le', 1.42], [1, 'g', 71.25], [1, 'le', 1.523075], [1, 'le', 0.165], [1, 'g', 8.675]]\n",
      "1: [[2, 'le', 0.335], [2, 'g', 2.56], [1, 'g', 12.18], [1, 'le', 0.36], [1, 'le', 1.42], [1, 'g', 71.25], [1, 'le', 1.523075], [1, 'g', 0.165], [1, 'le', 9.48]]\n",
      "1: [[2, 'le', 0.335], [2, 'g', 2.56], [1, 'g', 12.18], [1, 'le', 0.36], [1, 'le', 1.42], [1, 'g', 71.25], [1, 'le', 1.523075], [1, 'g', 0.165], [1, 'g', 9.48]]\n",
      "1: [[2, 'le', 0.335], [2, 'g', 2.56], [1, 'g', 12.18], [1, 'le', 0.36], [1, 'le', 1.42], [1, 'g', 71.25], [1, 'g', 1.523075], [1, 'e', 0.02]]\n",
      "1: [[2, 'le', 0.335], [2, 'g', 2.56], [1, 'g', 12.18], [1, 'le', 0.36], [1, 'le', 1.42], [1, 'g', 71.25], [1, 'g', 1.523075], [1, 'e', 0.09]]\n",
      "7: [[2, 'le', 0.335], [2, 'g', 2.56], [1, 'g', 12.18], [1, 'le', 0.36], [1, 'le', 1.42], [1, 'g', 71.25], [1, 'g', 1.523075], [1, 'e', 0.6]]\n",
      "2: [[2, 'le', 0.335], [2, 'g', 2.56], [1, 'g', 12.18], [1, 'le', 0.36], [1, 'g', 1.42], [2, 'le', 8.8], [2, 'le', 72.495], [2, 'le', 1.516585]]\n",
      "2: [[2, 'le', 0.335], [2, 'g', 2.56], [1, 'g', 12.18], [1, 'le', 0.36], [1, 'g', 1.42], [2, 'le', 8.8], [2, 'le', 72.495], [2, 'g', 1.516585], [2, 'le', 0.56]]\n",
      "3: [[2, 'le', 0.335], [2, 'g', 2.56], [1, 'g', 12.18], [1, 'le', 0.36], [1, 'g', 1.42], [2, 'le', 8.8], [2, 'le', 72.495], [2, 'g', 1.516585], [2, 'g', 0.56]]\n",
      "2: [[2, 'le', 0.335], [2, 'g', 2.56], [1, 'g', 12.18], [1, 'le', 0.36], [1, 'g', 1.42], [2, 'le', 8.8], [2, 'g', 72.495], [2, 'le', 1.51723], [2, 'le', 0.675]]\n",
      "2: [[2, 'le', 0.335], [2, 'g', 2.56], [1, 'g', 12.18], [1, 'le', 0.36], [1, 'g', 1.42], [2, 'le', 8.8], [2, 'g', 72.495], [2, 'le', 1.51723], [2, 'g', 0.675]]\n",
      "1: [[2, 'le', 0.335], [2, 'g', 2.56], [1, 'g', 12.18], [1, 'le', 0.36], [1, 'g', 1.42], [2, 'le', 8.8], [2, 'g', 72.495], [2, 'g', 1.51723], [1, 'le', 0.575]]\n",
      "2: [[2, 'le', 0.335], [2, 'g', 2.56], [1, 'g', 12.18], [1, 'le', 0.36], [1, 'g', 1.42], [2, 'le', 8.8], [2, 'g', 72.495], [2, 'g', 1.51723], [1, 'g', 0.575]]\n",
      "2: [[2, 'le', 0.335], [2, 'g', 2.56], [1, 'g', 12.18], [1, 'le', 0.36], [1, 'g', 1.42], [2, 'g', 8.8], [3, 'e', 1.5173]]\n",
      "3: [[2, 'le', 0.335], [2, 'g', 2.56], [1, 'g', 12.18], [1, 'le', 0.36], [1, 'g', 1.42], [2, 'g', 8.8], [3, 'e', 1.51796]]\n",
      "3: [[2, 'le', 0.335], [2, 'g', 2.56], [1, 'g', 12.18], [1, 'le', 0.36], [1, 'g', 1.42], [2, 'g', 8.8], [3, 'e', 1.5183200000000001]]\n",
      "3: [[2, 'le', 0.335], [2, 'g', 2.56], [1, 'g', 12.18], [1, 'g', 0.36]]\n",
      "7: [[2, 'g', 0.335], [7, 'le', 1.52745], [7, 'le', 3.42], [7, 'le', 3.19]]\n",
      "5: [[2, 'g', 0.335], [7, 'le', 1.52745], [7, 'le', 3.42], [7, 'g', 3.19]]\n",
      "1: [[2, 'g', 0.335], [7, 'le', 1.52745], [7, 'g', 3.42]]\n",
      "2: [[2, 'g', 0.335], [7, 'g', 1.52745]]\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "for x, label in [(r.conditions, r.label) for r in rules_dt]:\n",
    "    print(f\"{label}: {x}\")\n",
    "\n",
    "print(len(rules_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the class_label of sample given the C4.5 tree\n",
    "def predictClass(dt, x, feature_names):\n",
    "    currNode = dt\n",
    "    leafNode = dt.isLeafNode\n",
    "    while not leafNode:\n",
    "        idx = np.argwhere(feature_names == currNode.feature).ravel()\n",
    "        \n",
    "        # handling decision node that is discrete\n",
    "        if currNode.isFeatureDiscrete:\n",
    "            split_idx = np.argwhere(currNode.threshold == x[idx]).ravel()\n",
    "            \n",
    "            if len(split_idx):\n",
    "                currNode = currNode.childNodes[split_idx[0]]\n",
    "                leafNode = currNode.isLeafNode\n",
    "                \n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        # handling decision node that is continuous\n",
    "        else: \n",
    "            if x[idx] <= currNode.threshold:\n",
    "                currNode = currNode.childNodes[0] # go left in the decision path\n",
    "            else:\n",
    "                currNode = currNode.childNodes[1] # go right in the decision path\n",
    "\n",
    "            leafNode = currNode.isLeafNode\n",
    "    \n",
    "    y_pred = currNode.label\n",
    "    return y_pred\n",
    "\n",
    "# predict the class_label of sample given the list of rules\n",
    "def predictClassFromRules(rules, x):\n",
    "    \n",
    "    # iterate over all rules and return label from matching rule\n",
    "    for rule in rules:\n",
    "        isRuleTrue = rule.evaluate(x)\n",
    "        \n",
    "        if isRuleTrue:\n",
    "            return rule.label\n",
    "        \n",
    "    # if no rules matched print error message\n",
    "    print(f\"ERROR! Unable to find matching rule for: {x}\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree class that uses C4.5 implementation\n",
    "class DecisionTree:\n",
    "    \n",
    "    # if hyperparamters required, they are to be added here (ex. max_depth)\n",
    "    def __init__(self, feature_names):\n",
    "        self.clf = None                       # decision tree root node\n",
    "        self.rules = None                     # order set of Rule objects based on validation acuracy\n",
    "        self.feature_names = feature_names    # set of feature_names, used in decision tree construction\n",
    "    \n",
    "    def fit(self, x_train, y_train):\n",
    "        self.clf = buildTree(x_train, y_train, self.feature_names)\n",
    "    \n",
    "    def predict(self, x_test):\n",
    "        y_pred = []\n",
    "        for x in x_test:\n",
    "            y_pred.append(predictClass(self.clf, x, self.feature_names))\n",
    "            \n",
    "        return y_pred\n",
    "\n",
    "    # convert tree into set of Rule objects and apply rule post pruning\n",
    "    def prune(self, X_validation, Y_validation):\n",
    "        ruleSet = convertTreeToListOfRules(self.clf)\n",
    "        \n",
    "        for rule in ruleSet:\n",
    "            rule.pruneRule(X_validation, Y_validation)\n",
    "            \n",
    "        order = np.argsort([r.accuracy for r in ruleSet])[::-1]\n",
    "        self.rules = [ruleSet[i] for i in order]\n",
    "    \n",
    "    # predict from pruned set of rules\n",
    "    def predictFromPrunedTree(self, x_test):\n",
    "        y_pred = []\n",
    "        for x in x_test:\n",
    "            y_pred.append(predictClassFromRules(self.rules, x))\n",
    "            \n",
    "        return y_pred\n",
    "    \n",
    "# decision tree node that defines threshold, isLeafNode, class_label and childNodes list\n",
    "class dtNode:\n",
    "    \n",
    "    def __init__(self, threshold, isLeafNode, label, feature, isFeatureDiscrete):\n",
    "        self.threshold = threshold # threshold for the decision path, None if isLeafNode\n",
    "        self.isLeafNode = isLeafNode  # if current node is a leaf (terminal) node\n",
    "        self.label = label  # the class label, if not isLeafNode it is the majority class label\n",
    "        self.feature = feature # if not isLeafNode it is the feature to split on, otherwise None\n",
    "        self.isFeatureDiscrete = isFeatureDiscrete # check feature discrete or continuous, None if isLeafNode\n",
    "        self.childNodes = []\n",
    "        \n",
    "# Rule class to be used for rule post pruning\n",
    "class Rule:\n",
    "    \n",
    "    def __init__(self, classLabel):\n",
    "        self.conditions = []               # formatted as 2d list: [[feature, operator, value], ...]\n",
    "        self.label = classLabel            # class label if conditions satisified\n",
    "        self.accuracy = None               # accuracy of the rule, set by pruneRule function\n",
    "    \n",
    "    # prepend a condition to the rule, condition format [feature, operator, value]\n",
    "    def prependCondition(self, condition):\n",
    "        self.conditions.insert(0, condition)\n",
    "    \n",
    "    # evaluates the rule on given instance x, returns True or False\n",
    "    def evaluate(self, x):\n",
    "        result = []\n",
    "        \n",
    "        for condition in self.conditions:\n",
    "            ft_idx, op, value = condition\n",
    "            if op == 'e':\n",
    "                result.append(x[ft_idx] == value)\n",
    "                \n",
    "            elif op == 'le':\n",
    "                result.append(x[ft_idx] <= value)\n",
    "                \n",
    "            elif op == 'g':\n",
    "                result.append(x[ft_idx] > value)\n",
    "            \n",
    "        return all(result)\n",
    "    \n",
    "    # deter rule accuracy on validation set\n",
    "    def testRule(self, X_validation, Y_validation):\n",
    "        result = []\n",
    "        for x in X_validation:\n",
    "            result.append(self.evaluate(x))\n",
    "            \n",
    "        corr = len([y for y in Y_validation[result] if self.label == y])\n",
    "        total = len(Y_validation[result])\n",
    "        acc = corr / total if total != 0 else 0\n",
    "        \n",
    "        return acc\n",
    "    \n",
    "    # iteratively prune rule if validation accuracy does not drop\n",
    "    def pruneRule(self, X_validation, Y_validation):\n",
    "        \n",
    "        # find initial rule accuracy\n",
    "        self.accuracy = self.testRule(X_validation, Y_validation)\n",
    "        run = True\n",
    "        \n",
    "        # start iterative pruning of the rule\n",
    "        rule_conditions = self.conditions[:]\n",
    "        while(run):\n",
    "            \n",
    "            run = False\n",
    "            num_conditions = len(self.conditions)\n",
    "            \n",
    "            for i in range(num_conditions):\n",
    "                self.conditions = rule_conditions[:]\n",
    "                del self.conditions[i]\n",
    "                \n",
    "                acc = self.testRule(X_validation, Y_validation)\n",
    "\n",
    "                if acc > self.accuracy:\n",
    "                    rule_conditions = self.conditions[:]\n",
    "                    self.accuracy = acc\n",
    "                    run = True\n",
    "                    break\n",
    "                \n",
    "                elif i == num_conditions - 1:\n",
    "                    self.conditions = rule_conditions[:]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform CV with given number of iterations and folds\n",
    "def crossvalidation(clf, X, Y, iters=10, k=10, pruned=False):\n",
    "    numsamples = X.shape[0]\n",
    "\n",
    "    accuracy_scores = []\n",
    "    for i in range(iters):\n",
    "\n",
    "        # single iteration of k-fold CV\n",
    "        idxs = np.arange(numsamples)\n",
    "        folds = np.random.choice(idxs, size=(k, int(numsamples/k)), replace=False)\n",
    "\n",
    "        # obtain accuracy scores for k-fold CV\n",
    "        kfold_accuracy_scores = []\n",
    "        for j in range(k):\n",
    "            test_idx = folds[j]\n",
    "            train_idx = np.delete(folds, j, axis=0).ravel()\n",
    "\n",
    "            # decision tree fit on entire train set\n",
    "            if not pruned:\n",
    "                clf.fit(X[train_idx], Y[train_idx])\n",
    "                y_pred = clf.predict(X[test_idx])\n",
    "                \n",
    "            # decision tree fit on 80% of train set, hold out 20% for validation\n",
    "            else:\n",
    "                actual_train_size = int(0.8 * len(train_idx))\n",
    "                actual_train_idx = np.random.choice(train_idx, size=actual_train_size, replace=False)\n",
    "                validation_idx = np.array([i for i in train_idx if i not in actual_train_idx])\n",
    "                \n",
    "                clf.fit(X[actual_train_idx], Y[actual_train_idx])\n",
    "                clf.prune(X[validation_idx], Y[validation_idx])\n",
    "                y_pred = clf.predictFromPrunedTree(X[test_idx])\n",
    "\n",
    "            accuracy = accuracy_score(Y[test_idx], y_pred)\n",
    "            kfold_accuracy_scores.append(accuracy)\n",
    "\n",
    "        accuracy_scores.append(np.mean(kfold_accuracy_scores))\n",
    "    \n",
    "    return accuracy_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build classifier on glass dataset\n",
    "glass_clf = DecisionTree(glass_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glass Dataset\n",
      "10 times 10 fold CV: (0.95 CI)\n",
      "------------------------------\n",
      "C4.5 without pruning\n",
      "------------------------------\n",
      "Accuracy: 0.6381 +/- 0.0430\n",
      "------------------------------\n",
      "C4.5 with pruning\n",
      "------------------------------\n",
      "Accuracy: 0.3443 +/- 0.0886\n"
     ]
    }
   ],
   "source": [
    "# do 10 times 10 CV on tic glass dataset\n",
    "accuracy_scores = crossvalidation(glass_clf, glass_X, glass_Y, iters=10, k=10, pruned=False)\n",
    "pruned_accuracy_scores = crossvalidation(glass_clf, glass_X, glass_Y, iters=10, k=10, pruned=True)\n",
    "\n",
    "print(\"Glass Dataset\")\n",
    "print(\"10 times 10 fold CV: (0.95 CI)\")\n",
    "print(\"-\" * 30)\n",
    "print(\"C4.5 without pruning\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Accuracy: {np.mean(accuracy_scores):.4f} +/- {1.96*np.std(accuracy_scores, ddof=0):.4f}\")\n",
    "print(\"-\" * 30)\n",
    "print(\"C4.5 with pruning\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Accuracy: {np.mean(pruned_accuracy_scores):.4f} +/- {1.96*np.std(pruned_accuracy_scores, ddof=0):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build classifier on tic tac toe dataset\n",
    "tictactoe_clf = DecisionTree(tictactoe_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tic Tac Toe Dataset\n",
      "10 times 10 fold CV: (0.95 CI)\n",
      "------------------------------\n",
      "C4.5 without pruning\n",
      "------------------------------\n",
      "Accuracy: 0.8493 +/- 0.0239\n",
      "------------------------------\n",
      "C4.5 with pruning\n",
      "------------------------------\n",
      "Accuracy: 0.6252 +/- 0.0330\n"
     ]
    }
   ],
   "source": [
    "# do 10 times 10 CV on tic tac toe dataset\n",
    "accuracy_scores = crossvalidation(tictactoe_clf, tictactoe_X, tictactoe_Y, iters=10, k=10, pruned=False)\n",
    "pruned_accuracy_scores = crossvalidation(tictactoe_clf, tictactoe_X, tictactoe_Y, iters=10, k=10, pruned=True)\n",
    "\n",
    "print(\"Tic Tac Toe Dataset\")\n",
    "print(\"10 times 10 fold CV: (0.95 CI)\")\n",
    "print(\"-\" * 30)\n",
    "print(\"C4.5 without pruning\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Accuracy: {np.mean(accuracy_scores):.4f} +/- {1.96*np.std(accuracy_scores, ddof=0):.4f}\")\n",
    "print(\"-\" * 30)\n",
    "print(\"C4.5 with pruning\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Accuracy: {np.mean(pruned_accuracy_scores):.4f} +/- {1.96*np.std(pruned_accuracy_scores, ddof=0):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mnist dataset\n",
    "X_train, Y_train = loadlocal_mnist(\n",
    "        images_path='datasets/train-images.idx3-ubyte', \n",
    "        labels_path='datasets/train-labels.idx1-ubyte')\n",
    "\n",
    "X_test, Y_test = loadlocal_mnist(\n",
    "        images_path='datasets/t10k-images.idx3-ubyte', \n",
    "        labels_path='datasets/t10k-labels.idx1-ubyte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part a\n",
    "\n",
    "# objective function: interclass distance based on euclidean distance metric\n",
    "def objFn(means):\n",
    "    mu_t = [np.mean(means, axis=0)]\n",
    "    return np.sum(cdist(mu_t, means, 'euclidean'))\n",
    "    \n",
    "# bidirectional search algorithm\n",
    "def bidirectionalSearch(X, Y, iters):\n",
    "    numfeatures = X.shape[1]\n",
    "    sfs = []                        # initialize empty SFS list\n",
    "    sbs = list(range(numfeatures))  # initialize SBS list with all feature indexes\n",
    "    \n",
    "    # obtain indexes by class\n",
    "    nclass = len(np.unique(Y))\n",
    "    idxByClass = []\n",
    "    for x in np.unique(Y):\n",
    "        idxByClass.append(np.argwhere(Y == x).ravel())\n",
    "    \n",
    "    for k in range(iters):\n",
    "        print(f\"Iteration #: {k+1}\")\n",
    "        # select best feature\n",
    "        best_ftIdx = None\n",
    "        best_score = 0\n",
    "        \n",
    "        fwd = [i for i in sbs if i not in sfs]\n",
    "        for ftIdx in fwd:\n",
    "            currSet = sfs + [ftIdx]\n",
    "            currX = X[:, currSet]\n",
    "            means = [currX[idxByClass[i]].mean(axis=0) for i in range(nclass)]\n",
    "            score = objFn(means)\n",
    "            \n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_ftIdx = ftIdx\n",
    "        \n",
    "        # update SFS list\n",
    "        sfs.append(best_ftIdx)\n",
    "        \n",
    "        # remove worst feature\n",
    "        worst_ftIdx = None\n",
    "        best_score = 0\n",
    "        \n",
    "        bkwd = [i for i in sbs if i not in sfs]\n",
    "        for ftIdx in bkwd:\n",
    "            currSet = [i for i in sbs if i != ftIdx]\n",
    "            currX = X[:, currSet]\n",
    "            means = [currX[idxByClass[i]].mean(axis=0) for i in range(nclass)]\n",
    "            score = objFn(means)\n",
    "            \n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                worst_ftIdx = ftIdx\n",
    "        \n",
    "        # update SBS list\n",
    "        sbs.remove(worst_ftIdx)\n",
    "    \n",
    "    return sfs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Feature Set: 392 ***\n",
      "Iteration #: 1\n",
      "Iteration #: 2\n",
      "Iteration #: 3\n",
      "Iteration #: 4\n",
      "Iteration #: 5\n",
      "Iteration #: 6\n",
      "Iteration #: 7\n",
      "Iteration #: 8\n",
      "Iteration #: 9\n",
      "Iteration #: 10\n",
      "Iteration #: 11\n",
      "Iteration #: 12\n",
      "Iteration #: 13\n",
      "Iteration #: 14\n",
      "Iteration #: 15\n",
      "Iteration #: 16\n",
      "Iteration #: 17\n",
      "Iteration #: 18\n",
      "Iteration #: 19\n",
      "Iteration #: 20\n",
      "Iteration #: 21\n",
      "Iteration #: 22\n",
      "Iteration #: 23\n",
      "Iteration #: 24\n",
      "Iteration #: 25\n",
      "Iteration #: 26\n",
      "Iteration #: 27\n",
      "Iteration #: 28\n",
      "Iteration #: 29\n",
      "Iteration #: 30\n",
      "Iteration #: 31\n",
      "Iteration #: 32\n",
      "Iteration #: 33\n",
      "Iteration #: 34\n",
      "Iteration #: 35\n",
      "Iteration #: 36\n",
      "Iteration #: 37\n",
      "Iteration #: 38\n",
      "Iteration #: 39\n",
      "Iteration #: 40\n",
      "Iteration #: 41\n",
      "Iteration #: 42\n",
      "Iteration #: 43\n",
      "Iteration #: 44\n",
      "Iteration #: 45\n",
      "Iteration #: 46\n",
      "Iteration #: 47\n",
      "Iteration #: 48\n",
      "Iteration #: 49\n",
      "Iteration #: 50\n",
      "Iteration #: 51\n",
      "Iteration #: 52\n",
      "Iteration #: 53\n",
      "Iteration #: 54\n",
      "Iteration #: 55\n",
      "Iteration #: 56\n",
      "Iteration #: 57\n",
      "Iteration #: 58\n",
      "Iteration #: 59\n",
      "Iteration #: 60\n",
      "Iteration #: 61\n",
      "Iteration #: 62\n",
      "Iteration #: 63\n",
      "Iteration #: 64\n",
      "Iteration #: 65\n",
      "Iteration #: 66\n",
      "Iteration #: 67\n",
      "Iteration #: 68\n",
      "Iteration #: 69\n",
      "Iteration #: 70\n",
      "Iteration #: 71\n",
      "Iteration #: 72\n",
      "Iteration #: 73\n",
      "Iteration #: 74\n",
      "Iteration #: 75\n",
      "Iteration #: 76\n",
      "Iteration #: 77\n",
      "Iteration #: 78\n",
      "Iteration #: 79\n",
      "Iteration #: 80\n",
      "Iteration #: 81\n",
      "Iteration #: 82\n",
      "Iteration #: 83\n",
      "Iteration #: 84\n",
      "Iteration #: 85\n",
      "Iteration #: 86\n",
      "Iteration #: 87\n",
      "Iteration #: 88\n",
      "Iteration #: 89\n",
      "Iteration #: 90\n",
      "Iteration #: 91\n",
      "Iteration #: 92\n",
      "Iteration #: 93\n",
      "Iteration #: 94\n",
      "Iteration #: 95\n",
      "Iteration #: 96\n",
      "Iteration #: 97\n",
      "Iteration #: 98\n",
      "Iteration #: 99\n",
      "Iteration #: 100\n",
      "Iteration #: 101\n",
      "Iteration #: 102\n",
      "Iteration #: 103\n",
      "Iteration #: 104\n",
      "Iteration #: 105\n",
      "Iteration #: 106\n",
      "Iteration #: 107\n",
      "Iteration #: 108\n",
      "Iteration #: 109\n",
      "Iteration #: 110\n",
      "Iteration #: 111\n",
      "Iteration #: 112\n",
      "Iteration #: 113\n",
      "Iteration #: 114\n",
      "Iteration #: 115\n",
      "Iteration #: 116\n",
      "Iteration #: 117\n",
      "Iteration #: 118\n",
      "Iteration #: 119\n",
      "Iteration #: 120\n",
      "Iteration #: 121\n",
      "Iteration #: 122\n",
      "Iteration #: 123\n",
      "Iteration #: 124\n",
      "Iteration #: 125\n",
      "Iteration #: 126\n",
      "Iteration #: 127\n",
      "Iteration #: 128\n",
      "Iteration #: 129\n",
      "Iteration #: 130\n",
      "Iteration #: 131\n",
      "Iteration #: 132\n",
      "Iteration #: 133\n",
      "Iteration #: 134\n",
      "Iteration #: 135\n",
      "Iteration #: 136\n",
      "Iteration #: 137\n",
      "Iteration #: 138\n",
      "Iteration #: 139\n",
      "Iteration #: 140\n",
      "Iteration #: 141\n",
      "Iteration #: 142\n",
      "Iteration #: 143\n",
      "Iteration #: 144\n",
      "Iteration #: 145\n",
      "Iteration #: 146\n",
      "Iteration #: 147\n",
      "Iteration #: 148\n",
      "Iteration #: 149\n",
      "Iteration #: 150\n",
      "Iteration #: 151\n",
      "Iteration #: 152\n",
      "Iteration #: 153\n",
      "Iteration #: 154\n",
      "Iteration #: 155\n",
      "Iteration #: 156\n",
      "Iteration #: 157\n",
      "Iteration #: 158\n",
      "Iteration #: 159\n",
      "Iteration #: 160\n",
      "Iteration #: 161\n",
      "Iteration #: 162\n",
      "Iteration #: 163\n",
      "Iteration #: 164\n",
      "Iteration #: 165\n",
      "Iteration #: 166\n",
      "Iteration #: 167\n",
      "Iteration #: 168\n",
      "Iteration #: 169\n",
      "Iteration #: 170\n",
      "Iteration #: 171\n",
      "Iteration #: 172\n",
      "Iteration #: 173\n",
      "Iteration #: 174\n",
      "Iteration #: 175\n",
      "Iteration #: 176\n",
      "Iteration #: 177\n",
      "Iteration #: 178\n",
      "Iteration #: 179\n",
      "Iteration #: 180\n",
      "Iteration #: 181\n",
      "Iteration #: 182\n",
      "Iteration #: 183\n",
      "Iteration #: 184\n",
      "Iteration #: 185\n",
      "Iteration #: 186\n",
      "Iteration #: 187\n",
      "Iteration #: 188\n",
      "Iteration #: 189\n",
      "Iteration #: 190\n",
      "Iteration #: 191\n",
      "Iteration #: 192\n",
      "Iteration #: 193\n",
      "Iteration #: 194\n",
      "Iteration #: 195\n",
      "Iteration #: 196\n",
      "Iteration #: 197\n",
      "Iteration #: 198\n",
      "Iteration #: 199\n",
      "Iteration #: 200\n",
      "Iteration #: 201\n",
      "Iteration #: 202\n",
      "Iteration #: 203\n",
      "Iteration #: 204\n",
      "Iteration #: 205\n",
      "Iteration #: 206\n",
      "Iteration #: 207\n",
      "Iteration #: 208\n",
      "Iteration #: 209\n",
      "Iteration #: 210\n",
      "Iteration #: 211\n",
      "Iteration #: 212\n",
      "Iteration #: 213\n",
      "Iteration #: 214\n",
      "Iteration #: 215\n",
      "Iteration #: 216\n",
      "Iteration #: 217\n",
      "Iteration #: 218\n",
      "Iteration #: 219\n",
      "Iteration #: 220\n",
      "Iteration #: 221\n",
      "Iteration #: 222\n",
      "Iteration #: 223\n",
      "Iteration #: 224\n",
      "Iteration #: 225\n",
      "Iteration #: 226\n",
      "Iteration #: 227\n",
      "Iteration #: 228\n",
      "Iteration #: 229\n",
      "Iteration #: 230\n",
      "Iteration #: 231\n",
      "Iteration #: 232\n",
      "Iteration #: 233\n",
      "Iteration #: 234\n",
      "Iteration #: 235\n",
      "Iteration #: 236\n",
      "Iteration #: 237\n",
      "Iteration #: 238\n",
      "Iteration #: 239\n",
      "Iteration #: 240\n",
      "Iteration #: 241\n",
      "Iteration #: 242\n",
      "Iteration #: 243\n",
      "Iteration #: 244\n",
      "Iteration #: 245\n",
      "Iteration #: 246\n",
      "Iteration #: 247\n",
      "Iteration #: 248\n",
      "Iteration #: 249\n",
      "Iteration #: 250\n",
      "Iteration #: 251\n",
      "Iteration #: 252\n",
      "Iteration #: 253\n",
      "Iteration #: 254\n",
      "Iteration #: 255\n",
      "Iteration #: 256\n",
      "Iteration #: 257\n",
      "Iteration #: 258\n",
      "Iteration #: 259\n",
      "Iteration #: 260\n",
      "Iteration #: 261\n",
      "Iteration #: 262\n",
      "Iteration #: 263\n",
      "Iteration #: 264\n",
      "Iteration #: 265\n",
      "Iteration #: 266\n",
      "Iteration #: 267\n",
      "Iteration #: 268\n",
      "Iteration #: 269\n",
      "Iteration #: 270\n",
      "Iteration #: 271\n",
      "Iteration #: 272\n",
      "Iteration #: 273\n",
      "Iteration #: 274\n",
      "Iteration #: 275\n",
      "Iteration #: 276\n",
      "Iteration #: 277\n",
      "Iteration #: 278\n",
      "Iteration #: 279\n",
      "Iteration #: 280\n",
      "Iteration #: 281\n",
      "Iteration #: 282\n",
      "Iteration #: 283\n",
      "Iteration #: 284\n",
      "Iteration #: 285\n",
      "Iteration #: 286\n",
      "Iteration #: 287\n",
      "Iteration #: 288\n",
      "Iteration #: 289\n",
      "Iteration #: 290\n",
      "Iteration #: 291\n",
      "Iteration #: 292\n",
      "Iteration #: 293\n",
      "Iteration #: 294\n",
      "Iteration #: 295\n",
      "Iteration #: 296\n",
      "Iteration #: 297\n",
      "Iteration #: 298\n",
      "Iteration #: 299\n",
      "Iteration #: 300\n",
      "Iteration #: 301\n",
      "Iteration #: 302\n",
      "Iteration #: 303\n",
      "Iteration #: 304\n",
      "Iteration #: 305\n",
      "Iteration #: 306\n",
      "Iteration #: 307\n",
      "Iteration #: 308\n",
      "Iteration #: 309\n",
      "Iteration #: 310\n",
      "Iteration #: 311\n",
      "Iteration #: 312\n",
      "Iteration #: 313\n",
      "Iteration #: 314\n",
      "Iteration #: 315\n",
      "Iteration #: 316\n",
      "Iteration #: 317\n",
      "Iteration #: 318\n",
      "Iteration #: 319\n",
      "Iteration #: 320\n",
      "Iteration #: 321\n",
      "Iteration #: 322\n",
      "Iteration #: 323\n",
      "Iteration #: 324\n",
      "Iteration #: 325\n",
      "Iteration #: 326\n",
      "Iteration #: 327\n",
      "Iteration #: 328\n",
      "Iteration #: 329\n",
      "Iteration #: 330\n",
      "Iteration #: 331\n",
      "Iteration #: 332\n",
      "Iteration #: 333\n",
      "Iteration #: 334\n",
      "Iteration #: 335\n",
      "Iteration #: 336\n",
      "Iteration #: 337\n",
      "Iteration #: 338\n",
      "Iteration #: 339\n",
      "Iteration #: 340\n",
      "Iteration #: 341\n",
      "Iteration #: 342\n",
      "Iteration #: 343\n",
      "Iteration #: 344\n",
      "Iteration #: 345\n",
      "Iteration #: 346\n",
      "Iteration #: 347\n",
      "Iteration #: 348\n",
      "Iteration #: 349\n",
      "Iteration #: 350\n",
      "Iteration #: 351\n",
      "Iteration #: 352\n",
      "Iteration #: 353\n",
      "Iteration #: 354\n",
      "Iteration #: 355\n",
      "Iteration #: 356\n",
      "Iteration #: 357\n",
      "Iteration #: 358\n",
      "Iteration #: 359\n",
      "Iteration #: 360\n",
      "Iteration #: 361\n",
      "Iteration #: 362\n",
      "Iteration #: 363\n",
      "Iteration #: 364\n",
      "Iteration #: 365\n",
      "Iteration #: 366\n",
      "Iteration #: 367\n",
      "Iteration #: 368\n",
      "Iteration #: 369\n",
      "Iteration #: 370\n",
      "Iteration #: 371\n",
      "Iteration #: 372\n",
      "Iteration #: 373\n",
      "Iteration #: 374\n",
      "Iteration #: 375\n",
      "Iteration #: 376\n",
      "Iteration #: 377\n",
      "Iteration #: 378\n",
      "Iteration #: 379\n",
      "Iteration #: 380\n",
      "Iteration #: 381\n",
      "Iteration #: 382\n",
      "Iteration #: 383\n",
      "Iteration #: 384\n",
      "Iteration #: 385\n",
      "Iteration #: 386\n",
      "Iteration #: 387\n",
      "Iteration #: 388\n",
      "Iteration #: 389\n",
      "Iteration #: 390\n",
      "Iteration #: 391\n",
      "Iteration #: 392\n",
      "Wall time: 1h 51min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "f = 392\n",
    "\n",
    "print(f\"*** Feature Set: {f} ***\")\n",
    "featureSet = bidirectionalSearch(X_train[:10000], Y_train[:10000], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Sets: [10, 50, 150, 392]\n",
      "Accuracies:    [0.5801, 0.8077, 0.9315, 0.9477]\n"
     ]
    }
   ],
   "source": [
    "# use knn and report accuracy\n",
    "fs = [10, 50, 150, 392]\n",
    "k = 3\n",
    "\n",
    "res = []\n",
    "for f in fs:\n",
    "    selectedFt = featureSet[:f]\n",
    "    knn = KNeighborsClassifier(k, n_jobs=4)\n",
    "    knn.fit(X_train[:10000, selectedFt], Y_train[:10000])\n",
    "    y_pred = knn.predict(X_test[:, selectedFt])\n",
    "    score = accuracy_score(Y_test, y_pred)\n",
    "    res.append(score)\n",
    "    \n",
    "print(f\"Features Sets: {fs}\")\n",
    "print(f\"Accuracies:    {res}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASoAAAEoCAYAAADv8rwkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAFu9JREFUeJzt3Xu0XGV9xvHvEy6JkkQTuZhwCVcR7JKEorAK2lAUA4qBroKARXShwVWp0IYqRV3QKhatgLbeCJISNKBYLgZFJcVLZCksEhohIVIBIwk5JASIBLkGfv3jfUcmw8ycmXPmnHkn5/msNevM2bf57X32PPvd757ZRxGBmVnJRnW7ADOz/jiozKx4DiozK56DysyK56Ays+I5qMyseA4qMxt2kuZKWidpWSvTO6jMrBuuAGa0OrGDysyGXUQsAh5rdXoHlZkVb+tuF2Bm5ZoxY0asX7++7fmWLFmyHHimatCciJgz0DocVGbW0Pr161m8eHHb80l6JiIO6lQdDioza6qEGxe4j8rMmoqIth/9kXQ18CtgX0mrJZ3WbHq3qMysqaFoUUXESe1M76Ays4ZabSENNQeVmTXloDKz4jmozKx4JQRVcVf9JH1d0qeG+DV+JumD+fl7Jd08BK9xrqRvdHq5LbzucZJWSXpS0rThfv1WSNpdUkjq6oFS0vmSvtXNGnrBUFz1a9ewBpWkH0v61zrDZ0p6WNLWEfHhiPj0cNUUEfMj4sjBLEPSdEmra5b72Yj44OCqG5AvAGdExNiI+N/akZI+LeluSZsknV9n/MmSfi/pj5JukDSx0Qvlv9tSSU9IWi/pFkm7d3JlmpG0UtLbhmjZ0yW9mAO/8rixA8u9QtJnOlHjcBhISPV8UJG+MX2KJNUMPwWYHxGbhrmeLdEUYHmT8fcBHwN+UDtC0huAS0l/j52Ap4Cv1luIpL2BK4HZwKuAPfK0Lw6i9tKsyYFfeRzT7YK60QodiUF1AzAReEtlgKQJwLtIO/1mRxxJ20v6vqQNkh6T9AtJo/K4yG8W6sw3Ic/3iKTH8/Nd6hUk6f2Sbs3PP1ZzBH1e0hV53AckrZC0UdIDkk7Pw7cDfghMrppvcu1phaR3S1qe1+VnkvarGrdS0tmS7pL0B0nfkTSmQb2jJH0yt3rWSbpS0qskjZb0JLAV8GtJ99ebPyLmRcQPgY11Rr8XuDEiFkXEk8CngL+WNK7OtFOB30XELZFsjIhrI+LBqjrPkXS/pEclXdOodZbrv1xSn6SHJH1G0lZV4z9Ute3vkXSgpG8CuwE35m3+sTztIZJ+mbfzryVNr1rOHpJ+npezENi+Xj396W/dJH1X6QzhD5IW5QMAkmblbVzZz27Mw5vty9OVPhD5cUkPA/+Vh79LqTW7Ia/vG6vm/3jejhsl3SvpiIGsZ8WIC6qIeBq4Bnhf1eATgN9ExK/rzDIbWA3sQDrCnwu0shVGkf6gU0g789PAl1uo7/OVoyewH/BIrhdgHSlQxwMfAC6RdGBE/BE4is2PvmuqlyvpdcDVwFl5XW4ivcG2rZrsBNL9efYA3gi8v0GZ78+Pw4E9gbHAlyPi2Vw3wAERsVd/61vHG4A//R0i4n7gOeB1daa9E3i9pEskHS5pbM34jwLHAn8JTAYeB77S4HXnAZuAvYFpwJFApQ/xeOB80j4zHng38GhEnAI8CByTt/nnJe1Mail+hnRAPBu4VtIO+XWuApaQAurTwKktbJN6+lu3HwL7ADuSttN8gPyl3PlAZT9rtYX22rw+U4BZkg4E5gKnA68htYIX5IPVvsAZwJsiYhzwDmDlANeTXPfICqpsHnC8pFfk39+Xh9XzPDAJmBIRz0fEL6KFrRARj+aj+1MRsRG4gLRTtSTXdgPwpYi4KS/zBxFxf249/By4maqWYT/eA/wgIhZGxPOkfqRXAH9RNc1/RMSaiHgMuJHUYqnnvcDFEfFAbvX8M3CiOnNKMBb4Q82wPwAva1FFxAPAdGBnUpivzy2BSmCdDnwiIlZHxLOksPmb2jol7UQK+rMi4o8RsQ64BDgxT/JB0hv7jrzt74uI3zeo/2+BmyLipoh4MSIWAouBoyXtBrwJ+FQO9UWk7dzM5NxiqTxOaGXdImJubmFWxh0g6VX9vFYzLwLn5bqfBj4EXBoRt0fECxExD3gWOAR4ARgN7C9pm4hYmQ84AzYigyoibiW1VGZK2pO081zVYPJ/J/Wp3JxPt85p5TUkvVLSpfn06AlgEfDq6tOJflwO3BsRn6ta5lGSblM6Bd0AHE3rpw6TgT+9uSLiRWAV6U1e8XDV86dIodHvsvLzrUktzsF6ktRqqTae+qeJRMRtEXFCROxACu23Ap/Io6cA11fe5MAK0puots4pwDZAX9W0l5JaIwC7Aq2+0aaQDoIbqpZ1GOlgNxl4PLeAKxoFXsWaiHh11aPSum64bpK2knRhPi18gpdaMwM6zcweiYjqW6ZMAWbXrOeuwOSIuI/Ucj8fWCfp25ImD/SFBxJSW0RQZVeSWlKnADdHxNp6E+Wj0uyI2BM4BvjHqvPtp4BXVk3+2qrns4F9gYMjYjzpDQRQ24n/MjkM9wVOqxo2GriW1BLaKSJeTTp9qyyvv7/MGtLOVVmeSDvWQ/3V09+ySKe2m4C627BNy4EDKr/kA8lo4P/6mzEi7gCuA/4sD1oFHFXzRh8TEbXrvIrUGti+arrxEfGGqvGNTmNrt/sq4Js1r7ldRFwI9AETlPoUK3brb70aaLZuJwMzgbeRLjLsnudptq8025frzbMKuKDm9V8ZEVcDRMRVEXEYaT8J4HMMwkgPqreRmrCNTvsqHYZ75zf2E6Sj1gt59FLg5HwEm8Hmp3bjSP1SG3In53mtFCXpKHL/Q25iV2xLesM+AmzK01V/pGEt8JomzftrgHdKOkLSNqQgfRb4ZSt11bga+IfcMTwW+CzwnWjxiqmkbZQ66kcBW0saU9XSnA8cI+kt+Q39r8B1kU6fa5dzmFIn947599eT+o9uy5N8HbhA0pQ8fgdJM2uXExF9pNPoiySNzx3Ve0mq/D2/AZwt6c+V7F1ZJmm771m1uG/l+t+R94sxuTN6l3y6uBj4F0nbSjqMdPAbiGbrNo70t32UFD6frZm3tmZovi/XcxnwYUkH522ynaR3ShonaV9Jf5UPrs+Q3gcvNF9ccyM2qCJiJelNuh2woMmk+wD/Qzol+RXw1Yj4WR53JmlH20Dqt7mhar4vkvqA1pPeOD9qsbT3kDq7V+ilK3hfz2/Uj5IC53HSUfNPdUfEb0gB8kBuim/W1I6Ie0n9J/+ZazqG1An8XIt1VZsLfJN0Ovs70s74923Mfxlp5z2JdJr2NKllS0QsBz5MCqx1pDfd3zVYzgZSMN2tdLXxR8D1wOfz+C+RttHNkjaS/g4HN1jW+0gHg3tI2/e/SadrRMR3SX2MV5FOQStXjgH+Dfhk3uZnR8QqUmvmXNJBZRXwT7y0n5+ca3iMdPC6sumWaqzZul1JOqV8KK/PbTXzXk7qP9ogqbLPNtuXXyYiFpMO8l8mba/7eOniy2jgQtJ+9jDpFPrcgaxkSTQU6WdmW4Zp06bFT37yk7bnmzhx4pLwHT7NbDgM1alcuxxUZtaUg8rMiuegMrPi9XxQ5UupXyJ9v+wb+fMqzabv/hqbjVAR0e/nCBvM1+lS2jbgoMqfvfkK8HbS9/HukLQgIu7pVHFm1l2ldKYP5nNUbwbui/Sds+eAb5M+w2JmW5ASPvA5mFO/nUkfqKtYTeMP9JlZjyqhRTWYoKp3vvuyNVK6B8+sQbyOmXVRrwfVatIXayt2IX1hdjOR7sEzB9yZbtaLej2o7gD2kbQH6XtNJ5K+S2VmW4hSOtMHHFQRsUnSGcCPSR9PmJu/1GpmW5CeDiqASHe/vKlDtZhZgXo+qMxsy+egMrPilRBUxf2nZDOzWm5RmVlDPX/Vz8xGBgeVmRXPQWVmxXNQmVnxHFRmVjR3pptZT3BQmVnxHFRmVjwHlZkVz0FlZkVzZ7qZ9QQHlZkVz0FlZsVzUJlZ8RxUZla0UjrTfeM8MyueW1Rm1lQJLSoHlZk15aAys+I5qMyseA4qMytaKVf9HFRm1pSDysyK56Ays+I5qMyseA4qMyuaO9PNrCf0fFBJWglsBF4ANkXEQZ0oyszK0fNBlR0eEes7sBwzK9CWElRmtgUrIagGe5uXAG6WtETSrE4UZGblqHSmt/votMG2qA6NiDWSdgQWSvpNRCyqniAHmEPMrEf1fIsqItbkn+uA64E315lmTkQc5I52MxuoAQeVpO0kjas8B44ElnWqMDMrQ6+f+u0EXC+pspyrIuJHHanKzIpRwqnfgIMqIh4ADuhgLWZWoJ4OKjPb8vkrNGbWExxUZlY8B5WZFc9BZWbFc1CZWdHcmW5mPcFBZWbFc1CZWfEcVGZWPAeVmRXNnelm1hMcVGZWPAeVmRWvhKAa7D3TzcyGnFtUZtZUCS0qB5WZNeSrfmbWExxUZlY8B5WZFc9BZWbFc1CZWdHcmW5mPcFBZWbFc1CZWfEcVGZWPAeVmRXNnelm1hMcVGZWPAeVmRXPQWVmRSulj6rfG+dJmitpnaRlVcMmSloo6bf554ShLdPMRrJW7vB5BTCjZtg5wC0RsQ9wS/7dzLZAlVZVO49O6zeoImIR8FjN4JnAvPx8HnBsh+sys0KUEFQD7aPaKSL6ACKiT9KOHazJzApSQh/VkHemS5oFzBrq1zGzodHLQbVW0qTcmpoErGs0YUTMAeYASOr+GptZy3rmql8DC4BT8/NTge91phwzK01P9FFJuhqYDmwvaTVwHnAhcI2k04AHgeM7XpmZFaGEFlW/QRURJzUYdUSHazGzAvVEUJnZyOagMrOildKZ7qAys6YcVGZWPAeVmRXPQWVmxXNQmVnR3JluPae/HVbSMFViw6mEoBroV2jMzIaNW1Rm1lQJLSoHlZk15aAys+I5qMysaL7qZ2Y9wUFlZsVzUJlZ8RxUZlY8B5WZFc2d6WbWExxUZlY8B5WZFc9BZWbFc1CZWdHcmW5Ww/e7KpODysyKV0JQ+cZ5ZlY8t6jMrKkSWlQOKjNrykFlZkXzVT8z6wkOKjMrXglB1e9VP0lzJa2TtKxq2PmSHpK0ND+OHtoyrQSSmj5KX74NTOX0r51Hp7Xy8YQrgBl1hl8SEVPz46bOlmVmpSghqPo99YuIRZJ27/grm1nxSulMH8wHPs+QdFc+NZzQsYrMrCgltKgGGlRfA/YCpgJ9wEWNJpQ0S9JiSYsH+Fpm1kUlBNWArvpFxNrKc0mXAd9vMu0cYE6etvttSDNrSwmnfgMKKkmTIqIv/3ocsKzZ9GbWu3oiqCRdDUwHtpe0GjgPmC5pKhDASuD0IazRzLqklM70Vq76nVRn8OVDUIt1me8HZfX0RFCZ2cjmoDKz4pUQVL5xnpkVzy0qM2uqhBaVg8rMGuqZq35mNrI5qMyseA4qMyueg8rMiuegMrOiuTPdzHqCg8rMiuegMrPiOajMrHgOKjMrmjvTreMGez8p32/K6nFQmVnxHFRmVjwHlZkVz0FlZkUrpTPdd/g0s+K5RWVmTZXQonJQmVlTDiprSwk7jI08Jex3Dioza8pBZWZFK+Wqn4PKzJpyUJlZ8RxUZlY8B5WZFc9BZWZFK6Uzvd+v0EjaVdJPJa2QtFzSmXn4REkLJf02/5ww9OWObJIG9TAbiEpYtfPotFa+67cJmB0R+wGHAB+RtD9wDnBLROwD3JJ/N7MtTE8EVUT0RcSd+flGYAWwMzATmJcnmwcc2/HqzKzrSgiqtvqoJO0OTANuB3aKiL68In2Sdux4dWbWVaX0UbUcVJLGAtcCZ0XEE632eUiaBcwaWHlm1m09E1SStiGF1PyIuC4PXitpUm5NTQLW1Zs3IuYAc/Jyur/GZtaWEoKqlat+Ai4HVkTExVWjFgCn5uenAt/rfHlmZq21qA4FTgHulrQ0DzsXuBC4RtJpwIPA8UNTopl1Uwktqn6DKiJuBRp1SB3R2XJGtsH+Xz6zodATQWVmI1fPXfUzs5HJQWVmxXNQmVnxHFRmVjwHlZkVzZ3pZtYTHFS2GX9OykrkoDKz4jmozKx4DiozK5o7082sJziozKx4DiozK14JQdXKf6ExM+sqt6jMrKkSWlQOKjNryFf9zKwnOKjMrHgOKjMrnoPKzIrnoDKzorkz3cx6goPKzIrnoDKz4jmozKx4DiozK5o7082sJziozKx4DiozK56DysyKV0JQ9XvjPEm7SvqppBWSlks6Mw8/X9JDkpbmx9FDX66ZjUSttKg2AbMj4k5J44AlkhbmcZdExBeGrjwz66aeueoXEX1AX36+UdIKYOehLszMylBCULV1z3RJuwPTgNvzoDMk3SVprqQJHa7NzApQaVW18+i0loNK0ljgWuCsiHgC+BqwFzCV1OK6qMF8syQtlrS4A/Wa2TArIahauuonaRtSSM2PiOty8Wurxl8GfL/evBExB5iTp+t+G9LM2lLCqV+/QSVJwOXAioi4uGr4pNx/BXAcsGxoSjSzbumZznTgUOAU4G5JS/Owc4GTJE0FAlgJnD4kFZpZV/VEUEXErYDqjLqp8+WYWWl6IqjMbGRzUJlZ8RxUZla0XupMN7MRzEFlZsVzUJlZ8RxUZlY8B5WZFa2UzvS27p5gZtYNblGZWVMltKgcVGbWlIPKzIrnoDKz4jmozKxopVz1c1CZWVMjMajWA7+v+n37PKxUrm9wSq6v5Nqg8/VNGeiMIy6oImKH6t8lLY6Ig4azhna4vsEpub6Sa4Oy6htxQWVmvcdBZWZFc2d6MqfLr98f1zc4JddXcm1QUH0lBJVKKMLMyrT11lvH+PHj257v8ccfX9LJPrZut6jMrHAlNGa6cvcESTMk3SvpPknndKOGZiStlHS3pKUl/Ct6SXMlrZO0rGrYREkLJf02/5xQWH3nS3oob8Olko7uYn27SvqppBWSlks6Mw8vYhs2qa+IbVjCv3Qf9qCStBXwFeAoYH/SPzLdf7jraMHhETG1kEvEVwAzaoadA9wSEfsAt+Tfu+UKXl4fwCV5G06NiG7+H8hNwOyI2A84BPhI3udK2YaN6oMub8OBhNQWEVTAm4H7IuKBiHgO+DYwswt19IyIWAQ8VjN4JjAvP58HHDusRVVpUF8xIqIvIu7MzzcCK4CdKWQbNqmvCCM1qHYGVlX9vpqC/ihZADdLWiJpVreLaWCniOiDtKMDO3a5nnrOkHRXPjXs2qlpNUm7A9OA2ylwG9bUBwVsw5EaVPX+PXz3e+s2d2hEHEg6Pf2IpLd2u6Ae9DVgL2Aq0Adc1N1yQNJY4FrgrIh4otv11KpTX3HbsFu6EVSrgV2rft8FWNOFOhqKiDX55zrgetLpamnWSpoEkH+u63I9m4mItRHxQkS8CFxGl7ehpG1IITA/Iq7Lg4vZhvXqK2UbjtQW1R3APpL2kLQtcCKwoAt11CVpO0njKs+BI4FlzefqigXAqfn5qcD3uljLy1QCIDuOLm5DSQIuB1ZExMVVo4rYho3qK2UblhBUXfnAZ77M+kVgK2BuRFww7EU0IGlPUisK0ufMrup2fZKuBqaTvlG/FjgPuAG4BtgNeBA4PiK60qHdoL7ppFOWAFYCp1f6g7pQ32HAL4C7gRfz4HNJ/UBd34ZN6juJLm/DUaNGxZgxY9qe7+mnn+7oBz79yXQza2jUqFExevTotud75pln/Ml0Mxs+JTRmHFRm1pSDysyK56Ays6IN1VW8dvlfuptZU0Px8YR2b0zgFpWZNdXpFlXVjQneTvoA+B2SFkTEPY3mcYvKzJoaghZV2zcmcIvKzJoagj6qejcmOLjZDA4qM2vmx6RvHLRrTM1NJ+dEROU+8G3fmMBBZWYNRUS9GyIOVts3JnAflZkNt7ZvTOAWlZkNq4jYJOkM0mll5cYEy5vN4y8lm1nxfOpnZsVzUJlZ8RxUZlY8B5WZFc9BZWbFc1CZWfEcVGZWPAeVmRXv/wFjnCVBhgOM1QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# part b\n",
    "\n",
    "# plot visualization for each set of features\n",
    "for f in fs:\n",
    "    selectedFt = featureSet[:f]\n",
    "    pixels = np.zeros(28*28, dtype=int)\n",
    "    pixels[selectedFt]=1\n",
    "    plane = pixels.reshape(28, 28)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    cax = plt.imshow(plane, cmap='gray', vmin=0, vmax=1)\n",
    "    plt.colorbar(cax, ticks=[0, 1])    \n",
    "    plt.title(f\"Visualization of {f} Selected Features\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part c\n",
    "\n",
    "# compute within class scatter matrix\n",
    "def calcSw(mus, X, idxByClass):\n",
    "    \n",
    "    # find Sk: (x-mu)*(x-mu)^T for k classes\n",
    "    Sk = []\n",
    "    for idx, mu in zip(idxByClass, mus):\n",
    "        zero_mean_x = X[idx] - mu\n",
    "        cov = np.matmul(zero_mean_x.T, zero_mean_x)\n",
    "        Sk.append(cov)\n",
    "        \n",
    "    return np.sum(Sk, axis=0)\n",
    "        \n",
    "# compute between class scatter mtarix\n",
    "def calcSb(mus, idxByClass):\n",
    "    mu_total = np.mean(mus, axis=0)\n",
    "    \n",
    "    # find Sb: N_k*(mu_k-mu)*(mu_k-mu)^T\n",
    "    Sb = []\n",
    "    for idx, mu in zip(idxByClass, mus):\n",
    "        N_k = len(idx)\n",
    "        mu_k_diffed = mu - mu_total\n",
    "        Sb_k = np.outer(mu_k_diffed, mu_k_diffed) * N_k\n",
    "        Sb.append(Sb_k)\n",
    "    \n",
    "    return np.sum(Sb, axis=0)    \n",
    "\n",
    "# compute W* by finding eigenvectors\n",
    "def calcW(Sw, Sb, numclass):\n",
    "    Sw_inv = np.linalg.pinv(Sw)\n",
    "    Sw_inv_Sb = np.matmul(Sb, Sw_inv)\n",
    "    \n",
    "    # find eigenvalues and eigenvecs\n",
    "    eig_vals, eig_vecs = np.linalg.eig(Sw_inv_Sb)\n",
    "    \n",
    "    # compute W\n",
    "    order = np.argsort(eig_vals)[::-1]\n",
    "    W = eig_vecs[:, order[:numclass]].T\n",
    "    \n",
    "    return np.real(W)\n",
    "\n",
    "# compute LDA transformation\n",
    "def lda(X, Y=None, W=None):\n",
    "    \n",
    "    # compute transformation matrix W if not provided\n",
    "    if W is None:\n",
    "        # obtain indexes by class\n",
    "        nclass = len(np.unique(Y))\n",
    "        idxByClass = []\n",
    "        for x in np.unique(Y):\n",
    "            idxByClass.append(np.argwhere(Y == x).ravel())\n",
    "        \n",
    "        # find class means\n",
    "        mus = [X[idxByClass[i]].mean(axis=0) for i in range(nclass)]\n",
    "        \n",
    "        # use Sw and Sb to find optimal W by solving eigenvalue problem\n",
    "        Sw = calcSw(mus, X, idxByClass)\n",
    "        Sb = calcSb(mus, idxByClass)\n",
    "        W = calcW(Sw, Sb, nclass)\n",
    "    \n",
    "    # compute new_X using transformation matrix W\n",
    "    new_X = X @ W.T\n",
    "    \n",
    "    return new_X, W\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST Dataset\n",
      "Using kNN with LDA\n",
      "--------------------\n",
      "Accuracy: 0.8964\n"
     ]
    }
   ],
   "source": [
    "# use knn with LDA and report accuracy\n",
    "k = 3\n",
    "\n",
    "# apply LDA\n",
    "new_X_train, W = lda(X_train[:10000], Y_train[:10000])\n",
    "new_X_test, _ = lda(X_test, W=W)\n",
    "\n",
    "# run knn\n",
    "knn = KNeighborsClassifier(k, n_jobs=4)\n",
    "knn.fit(new_X_train, Y_train[:10000])\n",
    "y_pred = knn.predict(new_X_test)\n",
    "score = accuracy_score(Y_test, y_pred)\n",
    "\n",
    "print(\"MNIST Dataset\")\n",
    "print(\"Using kNN with LDA\")\n",
    "print(\"-\" * 20)\n",
    "print(f\"Accuracy: {np.mean(score):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:syde675-project]",
   "language": "python",
   "name": "conda-env-syde675-project-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
